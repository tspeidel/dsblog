<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Alternative Stats</title>
    <link>https://alternative-stats.netlify.com/post.html</link>
    <description>Recent content in Posts on Alternative Stats</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Thomas Speidel</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="/post.html" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Fixing a Table for Improved Readibility</title>
      <link>https://alternative-stats.netlify.com/post/fixing-a-table-for-improved-readibility.html</link>
      <pubDate>Tue, 06 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/fixing-a-table-for-improved-readibility.html</guid>
      <description>&lt;p&gt;I recently came across a fairly simple table of results. Being affected by an incurable condition called “graphical and tabular intolerance disorder”, I felt compelled to do something.&lt;/p&gt;
&lt;p&gt;The table comes from the US Open Dataset initiative. In particular, the Federal Aviation Interactive Reporting System (FAIRS). You can read more about it &lt;a href=&#34;https://www.gsa.gov/policy-regulations/policy/aviation-management-policy/aviation-regulations-and-guidance-overview/report-government-aircraft-data&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The original table is contained in the &lt;a href=&#34;https://www.gsa.gov/cdnstatic/FY_2015_Aviation_Open_Data_Set__dtd_04-08-16.xlsx&#34;&gt;Excel spreadsheet&lt;/a&gt; worksheet &lt;code&gt;Table 4 Total Costs&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;avi.table4.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;This is a poorly formatted table. In the 1981 article “&lt;a href=&#34;https://www.stat.washington.edu/pds/stat423/Documents/Ehrenberg.numeracy.pdf&#34;&gt;The Problem of Numeracy&lt;/a&gt;” (The American Statistician), Ehrenberg provides a number of valuable suggestions to improve the way data is presented.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Lack of numeracy is due mainly to the way data are presented. Most tables of data can be improved by following a few simple rules, such as drastic rounding, ordering the rows of a table by size, and giving a brief verbal summary of the data&lt;/em&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;More than thirty years later, Ehrenberg’s suggestions are echoed by Swires-Hennessy in &lt;a href=&#34;https://www.amazon.com/Presenting-Data-Communicate-Message-Effectively/dp/1118489594&#34;&gt;Presenting Data: How to Communicate Your Message Effectively&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here, I will incorporate some of the best practices to improve the display of the information in this table. I’ll be using R, but for this task any spreadsheet tool will do. I’ll show the R code as I go along. Non-R users can skip these and jump to the end result.&lt;/p&gt;
&lt;div id=&#34;download-the-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Download the Data&lt;/h2&gt;
&lt;p&gt;First we download the data and assign it to the object &lt;code&gt;avi&lt;/code&gt; which is a dataframe:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;## Packages
library(readxl)
library(dplyr)
library(tibble)
library(ggplot2)
library(knitr)
library(kableExtra)


## Download data
url &amp;lt;- &amp;quot;https://www.gsa.gov/cdnstatic/FY_2015_Aviation_Open_Data_Set__dtd_04-08-16.xlsx&amp;quot;
file &amp;lt;- &amp;quot;avi.xlsx&amp;quot;
if (!file.exists(file)) download.file(url, file)

avi &amp;lt;- read_excel(&amp;quot;/home/tspeidel/GoogleDrive/dsblog/dsblog/avi.xlsx&amp;quot;, 
    sheet = &amp;quot;Table 4 Total Costs&amp;quot;, skip = 2)

kable(avi)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Department or Agency&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;FY 2013&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;FY 2014&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;FY 2015&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Agriculture&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;155395227&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;142286692&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;182766978&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Commerce&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11167070&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10523256&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11083859&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Energy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22100903&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;24322856&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;23549439&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Health and Human Services&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;-&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Homeland Security&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;226775706&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;233554545&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;187032343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Justice&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;72911197&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;40790749&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;30478568&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of State&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;361855973&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;250545091&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;243860040&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Transportation&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83684482&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;82519582&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;76481166&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of the Interior&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57436231&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;96191478&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;112175711&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Environmental Protection Agency&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;259722&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;48805&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;214898&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Aeronautics and Space Administration&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;167397561&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;213753911&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;152074855&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Science Foundation&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6996610&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6142732&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4199225&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Tennessee Valley Authority&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;679377&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;665687&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7487795&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Total&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1166660059&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1101345384&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1031404877&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;Ok that’s a good start.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;shortening-the-numbers&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Shortening the Numbers&lt;/h2&gt;
&lt;p&gt;We usually don’t require utmost precision in a summary table and having long numbers is just going to tax our cognitive abilities.&lt;/p&gt;
&lt;p&gt;Ehrenberg writes: “&lt;em&gt;Scanning different figures or doing mental arithmetic are forms of mental interruption. This explains why we have such difficulty using longer numbers&lt;/em&gt;”. Edward Tufte makes similar point in his work while the Nobel proze winner Herbert Simon provides much of the foundational rationale.&lt;/p&gt;
&lt;p&gt;We have around 9 figures. There’s absolutely no reason to preserve these. So we are going to divide them by 1,000,000 to ease our cognitive strain:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avi %&amp;gt;%
     mutate(`Department or Agency` = as.factor(`Department or Agency`)) %&amp;gt;%
     mutate_if(is.character, as.numeric) %&amp;gt;%
     mutate_if(is.numeric, funs(as.numeric(./10^6))) %&amp;gt;%
     as.tibble() -&amp;gt; avi
     
kable(avi)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Department or Agency&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2013&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2014&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2015&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Agriculture&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;155.395227&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;142.286692&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;182.766978&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Commerce&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.167070&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.523256&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.083859&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Energy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;22.100903&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.322856&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.549439&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Health and Human Services&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Homeland Security&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;226.775706&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;233.554545&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;187.032343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Justice&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72.911197&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.790749&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30.478568&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of State&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;361.855973&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;250.545091&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;243.860040&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Transportation&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;83.684482&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;82.519582&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;76.481166&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of the Interior&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57.436231&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;96.191478&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;112.175711&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Environmental Protection Agency&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.259722&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.048805&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.214898&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Aeronautics and Space Administration&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;167.397561&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;213.753911&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;152.074855&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Science Foundation&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.996610&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.142732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.199225&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Tennessee Valley Authority&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.679377&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.665687&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.487795&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Total&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1166.660059&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1101.345384&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1031.404877&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;That’s better. Notice how we still have too many degits. This is unecessary precision. We’ll get back to that later since we’ll do it in one pass when the table is ready.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;marginals&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Marginals&lt;/h2&gt;
&lt;p&gt;The next step is to add marginals. It would help if we had a column with the mean cost by department for the three years. This is important because it will provide the sorting order. R usually thinks vector-wise (or column-wise) and I’m too lazy to &lt;a href=&#34;https://www.rdocumentation.org/packages/reshape2/versions/1.4.3/topics/melt.data.frame&#34;&gt;melt&lt;/a&gt; the data. The little known &lt;code&gt;rowwise()&lt;/code&gt; function comes to the rescue:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avi %&amp;gt;%
     rowwise() %&amp;gt;% 
     mutate(`Mean Cost` = mean(c(`FY 2013`, `FY 2014`, `FY 2015`), na.rm = TRUE)) %&amp;gt;%
     ungroup() %&amp;gt;%
     as.tibble() -&amp;gt; avi

kable(avi)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Department or Agency&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2013&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2014&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2015&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mean Cost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Agriculture&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;155.395227&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;142.286692&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;182.766978&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;160.149632&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Commerce&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.167070&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.523256&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.083859&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.924728&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Energy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;22.100903&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.322856&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.549439&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.324399&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Health and Human Services&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NaN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Homeland Security&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;226.775706&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;233.554545&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;187.032343&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;215.787531&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Justice&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72.911197&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.790749&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30.478568&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;48.060171&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of State&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;361.855973&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;250.545091&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;243.860040&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;285.420368&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Transportation&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;83.684482&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;82.519582&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;76.481166&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;80.895077&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of the Interior&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57.436231&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;96.191478&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;112.175711&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;88.601140&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Environmental Protection Agency&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.259722&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.048805&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.214898&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.174475&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Aeronautics and Space Administration&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;167.397561&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;213.753911&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;152.074855&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;177.742109&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Science Foundation&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.996610&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.142732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.199225&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.779522&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Tennessee Valley Authority&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.679377&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.665687&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.487795&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.944286&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Total&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1166.660059&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1101.345384&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1031.404877&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1099.803440&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;order&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Order&lt;/h2&gt;
&lt;p&gt;The table appears to be sorted in alphabetical order. This is not ideal. Tufte suggests humnans are pretty good at finding information by eye scanning. What we are not good at is to sort the data by memory: we’ll loose track after a few rows of data. So let’s order the data, highest to lowest. What do we sort by? The mean cost, that’s what it’s for:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avi %&amp;gt;%
     arrange(desc(`Mean Cost`)) %&amp;gt;%
     as.tibble() -&amp;gt; avi

avi &amp;lt;- avi[c(2:14, 1), ] 
kable(avi)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Department or Agency&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2013&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2014&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;FY 2015&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Mean Cost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of State&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;361.855973&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;250.545091&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;243.860040&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;285.420368&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Homeland Security&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;226.775706&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;233.554545&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;187.032343&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;215.787531&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Aeronautics and Space Administration&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;167.397561&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;213.753911&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;152.074855&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;177.742109&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Agriculture&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;155.395227&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;142.286692&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;182.766978&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;160.149632&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of the Interior&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;57.436231&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;96.191478&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;112.175711&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;88.601140&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Transportation&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;83.684482&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;82.519582&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;76.481166&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;80.895077&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Justice&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72.911197&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.790749&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30.478568&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;48.060171&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Energy&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;22.100903&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;24.322856&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.549439&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;23.324399&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Commerce&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.167070&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.523256&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.083859&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10.924728&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Science Foundation&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.996610&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6.142732&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.199225&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;5.779522&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Tennessee Valley Authority&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.679377&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.665687&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7.487795&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2.944286&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Environmental Protection Agency&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.259722&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.048805&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.214898&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.174475&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Health and Human Services&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;NaN&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Total&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1166.660059&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1101.345384&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1031.404877&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1099.803440&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;back-to-the-number-of-figures&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Back to the number of figures&lt;/h2&gt;
&lt;p&gt;Now that we have a table let’s round off all the numbers. This is a bit tricky: if we round off all the numbers to 0 decimal places, any number below 1, like Tennessee, will get 0. It turns out we can apply a conditional formatting. This is a bit ugly, but here it goes:&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;avi %&amp;gt;%
     mutate_if(is.numeric, funs(if_else(. &amp;lt; 10, format(round(., 1), 1), format(round(., 0), 0)))) %&amp;gt;%
     as.tibble() -&amp;gt; avi

kable(avi)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Department or Agency&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;FY 2013&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;FY 2014&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;FY 2015&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Mean Cost&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of State&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;362&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;251&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;244&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;285&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Homeland Security&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;227&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;234&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;187&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;216&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Aeronautics and Space Administration&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;167&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;214&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;152&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;178&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Agriculture&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;155&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;142&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;183&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;160&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of the Interior&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;57&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;96&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;112&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;89&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Transportation&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;84&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;83&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;76&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;81&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Justice&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;73&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Energy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;22&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;24&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;23&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Commerce&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;National Science Foundation&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7.0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;6.1&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;4.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;5.8&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Tennessee Valley Authority&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.7&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;7.5&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;2.9&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Environmental Protection Agency&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.0&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.2&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;0.2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Department of Health and Human Services&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;NA&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Total&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1167&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1101&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1031&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;1100&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;prettify&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Prettify&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;kable(avi, &amp;quot;html&amp;quot;, align = &amp;quot;l&amp;quot;) %&amp;gt;%
  kable_styling(bootstrap_options = c(&amp;quot;striped&amp;quot;, &amp;quot;hover&amp;quot;, &amp;quot;condensed&amp;quot;)) %&amp;gt;%
  row_spec(nrow(avi), bold = T) %&amp;gt;%
  footnote(general = &amp;quot;*In millions of dollars*&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Department or Agency
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
FY 2013
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
FY 2014
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
FY 2015
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Mean Cost
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of State
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
362
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
251
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
244
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
285
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of Homeland Security
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
227
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
234
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
187
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
216
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
National Aeronautics and Space Administration
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
167
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
214
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
152
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
178
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of Agriculture
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
155
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
142
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
183
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
160
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of the Interior
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
57
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
96
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
112
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
89
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of Transportation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
84
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
83
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
76
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
81
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of Justice
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
73
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
41
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
48
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of Energy
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
22
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
24
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
23
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of Commerce
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
11
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
National Science Foundation
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
6.1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
4.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
5.8
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Tennessee Valley Authority
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.7
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
7.5
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2.9
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Environmental Protection Agency
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0.2
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
Department of Health and Human Services
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;&#34;&gt;
Total
&lt;/td&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;&#34;&gt;
1167
&lt;/td&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;&#34;&gt;
1101
&lt;/td&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;&#34;&gt;
1031
&lt;/td&gt;
&lt;td style=&#34;text-align:left;font-weight: bold;&#34;&gt;
1100
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;tfoot&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border: 0;&#34; colspan=&#34;100%&#34;&gt;
&lt;strong&gt;Note: &lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;padding: 0; border: 0;&#34; colspan=&#34;100%&#34;&gt;
&lt;sup&gt;&lt;/sup&gt; &lt;em&gt;In millions of dollars&lt;/em&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tfoot&gt;
&lt;/table&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>What You Aren’t Told About Data Science</title>
      <link>https://alternative-stats.netlify.com/post/what-you-aren-t-told-about-data-science.html</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/what-you-aren-t-told-about-data-science.html</guid>
      <description>&lt;p&gt;&lt;img src=&#34;scrubbing.jpg&#34; height=&#34;200px&#34; width=&#34;700px&#34; /&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Some time ago I started writing a post on data preparation which I never completed and eventually forgot. A recent LinkedIn post by Kevin Gray stimulated a rich conversation around: “&lt;a href=&#34;https://www.linkedin.com/feed/update/urn:li:activity:6352086326745096192&#34;&gt;Can Data Cleaning be automated?&lt;/a&gt;”. It reminded and enticed me to complete the post.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div id=&#34;data-cleaning-and-data-preparation&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data Cleaning and Data Preparation&lt;/h1&gt;
&lt;p&gt;When practitioners talk about data cleaning, they usually refer to a collection of tasks needed to &lt;strong&gt;make the data amenable for analysis&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Data is not necessarily invalid when we say they need to be cleaned. A common term in statistics that hasn’t fully caught-on in other areas is that of &lt;strong&gt;convenience data&lt;/strong&gt;: data that has been collected for reasons other than the purpose at task. Convenience data includes most of today’s “Big Data” and certainly most data collected for administrative purposes. Convenience data almost always require varying amounts of preparation because &lt;strong&gt;key variables for the task at hand may be missing&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In 2014 on the height of the “Big-Data” hype, &lt;a href=&#34;https://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html&#34;&gt;Steve Lohr&lt;/a&gt; from the New York Times highlighted what practitioners have known for long time, but that came as a surprise to many. Lohr writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Working data scientists spend most of their time preparing data for analysis, a process that includes data collection, assessment, and transformation. Building an analysis data set is the first “hands-on” step in predictive analytics; analysts understand that this task is essntial for effective model building, and they invest as much time as needed to get it right.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Lohr goes on to highlight software tools capable of “finding, cleaning and blending data so that it is ready to be analyzed”. Most practitioners are highly skeptical of such claims; and for good reasons: they fail to recognize the complexity of the task. Unsurprisingly, it appears none of these software tools have caught up with data scientists. But why?&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;judgment-and-foresight&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Judgment and Foresight&lt;/h1&gt;
&lt;p&gt;Kuhn and Johnson shed some light in their popular book “&lt;a href=&#34;https://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485&#34;&gt;Applied Predictive Modeling (2013)&lt;/a&gt;”. They write:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One of the first steps in the model building process is to transform, or encode, the original data structure into a form that is most informative for the model. This encoding process is critical and must be done with &lt;strong&gt;foresight into the analysis&lt;/strong&gt; that will be performed so that appropriate predictors can be elucidated from the original data.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;“&lt;strong&gt;Foresight into the analysis&lt;/strong&gt;” is the key sentence. Practitioners typically have a reasonable idea of what they are trying to achieve and what they do with the data is a reflection of that purpose. Let me illustrate how that “foresight” affects the choices we make with the data:&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;float: left; margin-right: 10px;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;&lt;br&gt; A fictitious customer purchase record: multiple rows per id
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Customer ID
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Purchase
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Item
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2015-06-15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
D
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;float: left; margin-right: 10px;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;&lt;br&gt; A fictitious customer purchase record: single row per id
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Customer ID
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Purchase Month
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
A Items
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
B Items
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
C Items
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
D Items
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
June
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
August
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
August
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;float: left; margin-right: 10px;&#34;&gt;
&lt;caption&gt;
&lt;span id=&#34;tab:unnamed-chunk-1&#34;&gt;Table 1: &lt;/span&gt;&lt;br&gt; A fictitious customer purchase record: multiple row per id and one row for each day from earliest purchase till today
&lt;/caption&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Customer ID
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Purchase
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
Item
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2015-06-15
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2015-06-16
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2015-06-17
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2017-12-30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-25
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
C
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-26
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
A
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-27
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2017-12-30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-05
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
D
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2013-08-06
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
…
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
3
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
2017-12-30
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
NA
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;All three data-sets are realizations of the same underlying data, a fictitious customer purchase record. Neither is right or wrong, yet they all represent different “foresight” into how we attempt to analyze the data. There could be hundreds of ways to represent these data and each one of them may address a different analytically objective.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;can-data-be-clean&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Can Data Be Clean?&lt;/h1&gt;
&lt;p&gt;So, what’s clean data? Notwithstanding data entry errors, it may not exist writes &lt;a href=&#34;http://www.mimno.org/articles/carpentry/&#34;&gt;David Mimno (2014)&lt;/a&gt; from Cornell University:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;To me these imply that there is some kind of pure or clean data buried in a thin layer of non-clean data, and that one need only hose the dataset of to reveal the hard porcelain underneath the muck. In reality, the process is more like deciding how to cut into a piece of material, or how much to plane down a surface. It’s not that there’s any real distinction between good and bad, it’s more that some parts are or knottier than others. &lt;strong&gt;Judgement is critical&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;Foresight and now judgement&lt;/strong&gt;: two very human traits, both hard to automate except in very narrow problems.&lt;/p&gt;
&lt;p&gt;We must also remind ourselves that clean data may not be achievable in the first place. With respect to data with errors, Bill Winkler provides plenty of examples on the complexities of &lt;a href=&#34;https://en.wikipedia.org/wiki/Record_linkage&#34;&gt;record linkage&lt;/a&gt; where exact matches may not be feasible to achieve (see &lt;a href=&#34;http://onlinelibrary.wiley.com/doi/10.1002/wics.1317/abstract&#34;&gt;Winkler, 2014&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://www.amazon.com/Advanced-Analytics-Methodologies-Driving-Business/dp/0133498603&#34;&gt;Chambers and Dinsmore (2014)&lt;/a&gt; write on the importance of this time consuming steps:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Working data scientists spend most of their time preparing data for analytical a process that includes data collection, assessment, and transformation. Building an analysis data set is the first (hands-on&amp;quot; step in predictive analytics; analysts understand that this task is &lt;strong&gt;essential for effective model building&lt;/strong&gt;, and they invest as much time as needed to get it right.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;why-the-surprise&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Why the Surprise?&lt;/h1&gt;
&lt;p&gt;For practitioners, it is hardly a surprise data preparation is tedious and time consuming requiring foresight and judgement. Why the surprise then? &lt;a href=&#34;https://cs.uwaterloo.ca/~ilyas/&#34;&gt;Ihab Ilyas&lt;/a&gt; a professor at the University of Waterloo explains In a podcast interview on &lt;a href=&#34;https://www.oreilly.com/ideas/why-data-preparation-frameworks-rely-on-human-in-the-loop-systems&#34;&gt;O’Reilly Data Show&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It has been also difficult to communicate these results to industry. And database practitioners, if you like, they were more into the well structured data and assuming a lot of good properties around this data, [and they were also] more interested in indexing this data, storing it, moving it from one place to another. And now, dealing with this large amount of diverse heterogeneous data with tons of errors, sidled across all business units in the same enterprise became a necessity. You cannot really avoid that anymore.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Perhaps the problem lies in part with analytically literacy: organizations have traditionally dealt with straight forward analytically needs for which the data at hand was sufficiently usable: &lt;strong&gt;filtering, joining, aggregating, adding, sorting&lt;/strong&gt; etc. For instance: &lt;em&gt;how many widgets were sold in store 11 in Q1 of 2016?&lt;/em&gt; In a typical organization, many inconsistencies of data were carried forward, at times unnoticed, and left to the consumer of the data to deal with. This paradigm no longer holds in the era of data as an asset where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the inconsistencies in the data may preclude more sophisticated analysis and certainly inferential and predictive objectives&lt;/li&gt;
&lt;li&gt;the data scientist both prepares and analyzes the data&lt;/li&gt;
&lt;li&gt;the data scientist expects to work with raw, unprocessed data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Both Ilyas and Mimno highlight one aspect of doing data analysis data scientists may struggle with: &lt;strong&gt;single source of the truth&lt;/strong&gt;. This concept helps IT design robust data warehouse systems, but is a misleading principle to adhere to when doing analysis.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;can-data-preparation-be-automated&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Can Data Preparation Be Automated?&lt;/h1&gt;
&lt;p&gt;In my view, the short answer is no. Attempts to automate this tedious and time consuming task have largely failed because we do not know how to address the underlying problem. This does not mean that attempts at &lt;em&gt;facilitating&lt;/em&gt; data preparation tasks have failed. On the contrary, there has been progress in this area. In a &lt;a href=&#34;file:///home/tspeidel/GoogleDrive/dsblog/GitHub/dsblog/content/post/2017-12-30-what-you-aren-t-told-about-data-science.html&#34;&gt;recent Data Skeptic podcast&lt;/a&gt;, Microsoft’s Joseph Sirosh reports that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Building on the latest research in program synthesis (PROSE) and data cleaning, Microsoft created a data wrangling technology that can drastically reduce the time that data scientists have to spend in coding and transforming data for machine learning. The way program synthesis works are, you give an input, the kind of data you want to wrangle, and the output you want to transform to, so you control the before and after.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I have not looked into these tools. Nonetheless, this seems significantly more tractable than auto-magically “&lt;em&gt;finding, cleaning and blending data so that it is ready to be analyzed&lt;/em&gt;”. A search in the academic literature reveals this to be an &lt;a href=&#34;https://scholar.google.ca/scholar?q=program+synthesis+%28PROSE%29+data+transformations&amp;amp;hl=en&amp;amp;as_sdt=0%2C5&amp;amp;as_vis=1&amp;amp;as_ylo=2015&amp;amp;as_yhi=&#34;&gt;active area of research&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;It remains to be seen whether these tools will become flexible enough for practitioners to use.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>I built this blog using R</title>
      <link>https://alternative-stats.netlify.com/post/i-built-this-blog-using-r.html</link>
      <pubDate>Sun, 01 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/i-built-this-blog-using-r.html</guid>
      <description>&lt;p&gt;Just a few notes for those wondering how I built this site. I’m utilizing R with Yahui’s fantastic package &lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34;&gt;blogdown&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;blogdown_win.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;Blogdown utilizes &lt;a href=&#34;https://gohugo.io/&#34;&gt;Hugo&lt;/a&gt; which is a website generator: it compiles a bunch of files so that they can be served in a website. The nice thing about Hugo is that being open source, it has a large community that contribute themes and plugins.&lt;/p&gt;
&lt;p&gt;While Hugo has many themes to choose from, I’ve had difficulties finding one that work well with blogdown. In the end, I’ve settled for the popular Academic.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;hugo_themes.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;While the blog is managed in R, the files are uoloaded in my GitHub repo. I tried to host the site in GitHub but I found it too cumbersome requiring too many workarounds. Yihui suggested I try &lt;a href=&#34;https://www.netlify.com/&#34;&gt;Netlify&lt;/a&gt;. I must say that was great advise because it has been a smooth ride: just link Netlify to your GitHub repo, change a couple of settings in Netlify and off you go.&lt;/p&gt;
&lt;p&gt;The next phase is to migrate to an RStudio server version I have running on DigitalOcean so that I can publish from anywhere I have internet access. &lt;a href=&#34;https://www.digitalocean.com/&#34;&gt;DigitalOcean&lt;/a&gt; is a friendly, easy to use VPS. I’ve had RStudio server running on their systems for about 2 years now. If you want to give it a try, click the link below.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://m.do.co/c/63128d4ca243&#34;&gt;&lt;img src=&#34;do.png&#34;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;If you want to create your own blog in R, here are some good references:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://bookdown.org/yihui/blogdown/&#34; class=&#34;uri&#34;&gt;https://bookdown.org/yihui/blogdown/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://livefreeordichotomize.com/2017/07/13/introducing-the-tuftesque-blogdown-theme/&#34; class=&#34;uri&#34;&gt;http://livefreeordichotomize.com/2017/07/13/introducing-the-tuftesque-blogdown-theme/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://livefreeordichotomize.com/2017/08/08/how-to-make-an-rmarkdown-website/&#34; class=&#34;uri&#34;&gt;http://livefreeordichotomize.com/2017/08/08/how-to-make-an-rmarkdown-website/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>The Flight Dataset</title>
      <link>https://alternative-stats.netlify.com/post/the-flight-dataset.html</link>
      <pubDate>Thu, 28 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/the-flight-dataset.html</guid>
      <description>&lt;p&gt;As I build this blog, I’ve been looking for expressive datasets to illustrate ideas and examples. For data management, I found the U.S. Department of Transportation’s (DOT) Bureau of Transportation Statistics delays and cancellation dataset appealing for two reasons: first, it contains a good mixture of variable types (date and time, categorical and numerical); recond, on a personal level, I’ve always been interested in aviation.&lt;/p&gt;
&lt;p&gt;This dataset is available from &lt;a href=&#34;https://www.kaggle.com/usdot/flight-delays&#34;&gt;Kaggle&lt;/a&gt;, or directly from DOT. You can find all the R code in my &lt;a href=&#34;https://github.com/tspeidel/dsblog/tree/master/content/post&#34;&gt;gitHub&lt;/a&gt; repo.&lt;/p&gt;
&lt;table class=&#34;table table-striped table-hover table-condensed&#34; style=&#34;margin-left: auto; margin-right: auto;&#34;&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
year
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
month
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
day
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
day.of.week
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
airline
&lt;/th&gt;
&lt;th style=&#34;text-align:right;&#34;&gt;
flight.number
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
tail.number
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
origin.airport
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
destination.airport
&lt;/th&gt;
&lt;th style=&#34;text-align:left;&#34;&gt;
scheduled.departure
&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AS
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
98
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
N407AS
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ANC
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
SEA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0005
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2336
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
N3KUAA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LAX
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
PBI
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0010
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
US
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
840
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
N171US
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
SFO
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
CLT
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0020
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AA
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
258
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
N3HYAA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
LAX
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
MIA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0020
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
2015
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
1
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
4
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
AS
&lt;/td&gt;
&lt;td style=&#34;text-align:right;&#34;&gt;
135
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
N527AS
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
SEA
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
ANC
&lt;/td&gt;
&lt;td style=&#34;text-align:left;&#34;&gt;
0025
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;The dataset contains 5,819,079 rows and 31. Here’s a quick visualization of origin and destination pairs by the number of flights.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;Figures/unnamed-chunk-4-1.png&#34; /&gt;&lt;!-- --&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Biostatistics and Policing: An Example of Application and the Role of Statistical Literacy in Today&#39;s Organizations</title>
      <link>https://alternative-stats.netlify.com/post/biostatistics-and-policing-an-example-of-application-and-the-role-of-statistical-literacy-in-today-s-organizations.html</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/biostatistics-and-policing-an-example-of-application-and-the-role-of-statistical-literacy-in-today-s-organizations.html</guid>
      <description>&lt;p&gt;The best past of my job is that, as &lt;a href=&#34;http://www.nytimes.com/2000/07/28/us/john-tukey-85-statistician-coined-the-word-software.html?mcubz=0&#34;&gt;John Tukey&lt;/a&gt; famously said, &lt;strong&gt;I get to play in everyone’ sandbox&lt;/strong&gt;. It also brings positive unintended ramifications: we get to cross-pollinate fields. Perhaps, none of this is clearer than how biostatistics helps with &lt;a href=&#34;http://press.anu.edu.au/node/162/download&#34;&gt;policing serious crime in Australia&lt;/a&gt;:&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;policing_resious_crime.jpg&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;One of the authors, Robyn Attewell, writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Most of my statistical perspective is grounded in biostatistics which is the application of statistics in the study of disease and, more generally, the human condition. This is an area in which statistical principles have been well accepted and applied. I do not mean that all doctors know what a chi-square test is or could interpret a logistic regression. However, advances in knowledge in epidemiology and the treatment of disease have occurred through research which has been undertaken with the application of sound statistical methodology. The evidence base for prevention and treatment of disease has moved from personal experience and chronicles of case histories to global randomised controlled trials, longitudinal cohort studies and meta-analyses. The movement within the fields of public health and medicine towards a quantitative evidence base is so strong that the pharmaceutical industry, for example, is very highly regulated. New drug treatments are not able to be registered or receive government subsidy unless supported by a structured compilation of efficacy and safety data. It has to be proven beyond reasonable doubt that new medications work and their positive impact on the target disease outweighs any negatives through adverse side effects.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Attewell’s experience mirrors mine (and I bet, that of many other statisticians), having too worked in &lt;a href=&#34;http://epi-research.org/&#34;&gt;biostatistics&lt;/a&gt; for many years and later migrated into energy.&lt;/p&gt;
&lt;p&gt;Perhaps not as homogeneous as in other fields - there are indeed isolated pockets of statistical excellence in the energy industry - I routinely come across areas that not only lack statistical principles, but where I perceive a mistrust in something that’s perceived as new and unfamiliar.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Do we over-simplify the statistical methods so that they can be grasped by our audience at the cost of being woefully wrong?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;True, statistics and data science aren’t easy and thinking probabilistically is admittedly hard. This presents a challenge for the statistician or the data scientist: do we over-simplify the statistical methods so that they can be grasped by our audience at the cost of being woefully wrong? Do we, instead engage in the daunting task of educating our audience in statistical principles? Or shall we present the finding as unquestionable dogma … hey, just trust the fancy math?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Statistics is hard. Multiple regression is hard. Figuring out the appropriate denominator is hard. These errors aren’t so elementary. Andrew Gelman, 2016.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://twitter.com/stephensenn?lang=en&#34;&gt;Stephen John Senn&lt;/a&gt; captures parts of this dilemma when he writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;On the other hand, the need for clear results cannot be cited as grounds for only ever using the simplest of techniques. Statistics is no different from other sciences in this respect. Just as we cannot insist that chemist determine pH using litmus paper because that is what the non-chemist remembers from school, so we cannot insist that statisticians restrict themselves to a simple T-test because this was state of the art in 1908.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Our colleagues who focus on &lt;strong&gt;machine learning&lt;/strong&gt; (&lt;strong&gt;ML&lt;/strong&gt;) face similar dilemmas, perhaps even more so, given that ML methods tend to be uninterpretable &lt;a href=&#34;https://www.nature.com/news/can-we-open-the-black-box-of-ai-1.20731&#34;&gt;black-boxes&lt;/a&gt;. Two recent papers that touch on this subjects are &lt;a href=&#34;http://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf&#34;&gt;Ribeiro&lt;/a&gt; et al. and &lt;a href=&#34;http://opim.wharton.upenn.edu/risk/library/WPAF201410-AlgorthimAversion-Dietvorst-Simmons-Massey.pdf&#34;&gt;Dietvorst&lt;/a&gt; et al.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;ribeiro.png&#34; /&gt; &lt;img src=&#34;dietvorst.png&#34; /&gt;&lt;/p&gt;
&lt;p&gt;There’s no question in my mind that we need to increase the level of statistical literacy. However, the job of filling the gap left by an educational system that has historically failed to teach statistics cannot be entirely left in the hands of applied statisticians and data scientists.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We teach our children the mathematics of certainty - geometry and trigonometry- but not the mathematics of uncertainty, statistical thinking. &lt;a href=&#34;https://en.wikipedia.org/wiki/Gerd_Gigerenzer&#34;&gt;Gert Gigerenzer&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;div id=&#34;what-to-do&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What to Do?&lt;/h2&gt;
&lt;p&gt;I see very encouraging signs in recent &lt;a href=&#34;https://en.wikipedia.org/wiki/Science,_technology,_engineering,_and_mathematics&#34;&gt;STEM&lt;/a&gt; graduates, anecdotally at least, since I see them much better prepared to recognize statistical problems.&lt;/p&gt;
&lt;p&gt;However, the issue remains for those who have not had a chance to upgrade their skills: &lt;strong&gt;how then, do we increase data and statistical literacy in the current leaders and decision makers?&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;vendors-consultants-and-hype-make-things-a-lot-harder&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Vendors, Consultants (and Hype) Make Things a Lot Harder&lt;/h2&gt;
&lt;p&gt;For the practicing statistician and data scientist, vendors and consultants are a double edge sword. On one hands they help by bringing to light how statistics, ML (or whatever catchy word du jour is in vogue) can help organizations; because they have a more direct communication channel with upper management, the message makes it to the top.&lt;/p&gt;
&lt;p&gt;On the other hand, they have little vested interests in educating, let alone provide a fair view of the landscape. And in the long run, this is damaging.&lt;/p&gt;
&lt;p&gt;Perhaps, none of this damage is clearer than what’s happening with IBM Watson in health care where the “&lt;a href=&#34;https://www.technologyreview.com/s/607965/a-reality-check-for-ibms-ai-ambitions/&#34;&gt;&lt;em&gt;unrealistic timelines or promises&lt;/em&gt;&lt;/a&gt;” are now becoming obvious and, perhaps, backfiring.&lt;/p&gt;
&lt;p&gt;I’m not too worried about health care where the unrealistic claims are usually met with a dismissive shrug, precisely because, as Attewel writes, statistical principles have been well accepted and applied in that field.&lt;/p&gt;
&lt;p&gt;But think about areas where statistical principles are not nearly as pervasive. Lack of statistical literacy, means our defense mechanism is unprepared. Instead, the receiver has to rely on faulty heuristics and anecdotes such as: “&lt;em&gt;I heard SmartCo is using this tool, so it must be good&lt;/em&gt;” with little science to back them up.&lt;/p&gt;
&lt;p&gt;With time, the organization realizes those promises never materialized, the claims were unrealistic, and preconceived notions are re-inforced after a brief hiatus of hope. In a field where there are no certain truths, it’s easy to throw away the baby with the bathwater.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;summary&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Data Science and Statistics, including more specialized branches, such as biostatistics, have wide applicability in many analytical problems&lt;/li&gt;
&lt;li&gt;Statistical literacy and critical thinking present a gap that is easily exploited&lt;/li&gt;
&lt;li&gt;We need to do a better job at educating people unfamiliar with data science and statistics, but this cannot be left entirely in the hands of the practitioner&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>10 Big Data Myths</title>
      <link>https://alternative-stats.netlify.com/post/10-big-data-myths.html</link>
      <pubDate>Fri, 25 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/10-big-data-myths.html</guid>
      <description>&lt;p&gt;Everyone seems to like top-10 lists and many organizations are interested in Big Data, so it seems timely to write my own top 10 list on Big Data. A premise is warranted. Those who know me, know how much I ditest the term “Big Data”. Yet, for good or worse, Big Data is here to stay and so it’s important that we try clarify what it is and it isn’t.&lt;/p&gt;
&lt;p&gt;see &lt;a href=&#34;https://dzone.com/articles/10-big-data-myths-exploded&#34; class=&#34;uri&#34;&gt;https://dzone.com/articles/10-big-data-myths-exploded&lt;/a&gt; Gartner: &lt;a href=&#34;https://www.forbes.com/sites/gartnergroup/2013/03/27/gartners-big-data-definition-consists-of-three-parts-not-to-be-confused-with-three-vs/#30da54dd42f6&#34; class=&#34;uri&#34;&gt;https://www.forbes.com/sites/gartnergroup/2013/03/27/gartners-big-data-definition-consists-of-three-parts-not-to-be-confused-with-three-vs/#30da54dd42f6&lt;/a&gt; Diego slides: &lt;a href=&#34;https://www.slideshare.net/kuonen/the-power-of-data-insights-big-data-as-the-fuel-and-analytics-as-the-engine-of-the-digital-transformation&#34; class=&#34;uri&#34;&gt;https://www.slideshare.net/kuonen/the-power-of-data-insights-big-data-as-the-fuel-and-analytics-as-the-engine-of-the-digital-transformation&lt;/a&gt; &lt;a href=&#34;https://www.newyorker.com/tech/elements/how-to-call-bullshit-on-big-data-a-practical-guide&#34; class=&#34;uri&#34;&gt;https://www.newyorker.com/tech/elements/how-to-call-bullshit-on-big-data-a-practical-guide&lt;/a&gt; &lt;a href=&#34;https://hbr.org/2016/11/what-artificial-intelligence-can-and-cant-do-right-now&#34; class=&#34;uri&#34;&gt;https://hbr.org/2016/11/what-artificial-intelligence-can-and-cant-do-right-now&lt;/a&gt;&lt;/p&gt;
&lt;div id=&#34;what-is-big-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;What is Big Data?&lt;/h2&gt;
&lt;p&gt;First thing first: definitions. What is Big Data? The hardest thing about Big Data is defining it. Conventionally, Big Data is defined in terms of the 3 or 4 V’s:&lt;/p&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;Volume&lt;/li&gt;
&lt;li&gt;Velocity&lt;/li&gt;
&lt;li&gt;Variety&lt;/li&gt;
&lt;li&gt;Veracity&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;For an overview of each V, I refer you to Diego Kuonen’s excellent [slides] here(&lt;a href=&#34;https://image.slidesharecdn.com/pdibddsmlmsftfeb12017-170201151005/95/the-power-of-data-insights-big-data-as-the-fuel-and-analytics-as-the-engine-of-the-digital-transformation-9-638.jpg?cb=1485961990&#34; class=&#34;uri&#34;&gt;https://image.slidesharecdn.com/pdibddsmlmsftfeb12017-170201151005/95/the-power-of-data-insights-big-data-as-the-fuel-and-analytics-as-the-engine-of-the-digital-transformation-9-638.jpg?cb=1485961990&lt;/a&gt;).&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;myths-facts&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Myths &amp;amp; Facts&lt;/h2&gt;
&lt;ol style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Big Data will enable analytics within the organization. Not necessarily. You don’t need Big Data to become more analytically mature. Many organizations have become analytically astute without Big Data. For instance, look at CERN, Capital One, Wal-Mart, AT&amp;amp;T. As friend Diego Kuonen writes, &lt;strong&gt;Big Data is mostly a data management infrastructure&lt;/strong&gt; problem, and less an analytical one.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Big Data provides a single source of the truth. No. As a long time analytics practitioner, I’ve always struggled with the idea of single source of the truth, which I recognize as being a useful ideal in designing data systems. But when it comes to making sense of data, it is common to have multiple sources of the truth. It all depends on the question one is trying to answer. Consider the trivial reporting of some metric for regulatory compliance vs. reporting for business improvement processes. The two metrics may be given the same name, they may involve the same calculations, but they may come from different systems designed for different purposes.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Big Data will make access to data easier No, or not yet.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Big Data is synonym of HADOOP Yes. While it is true that there are other standards, tools and technologies, the majority of the Big Data ecosystems are either based on HADOOP or strongly influenced by it. Big Data is becoming a substitute for HADOOP, Apache and any project revolving around them.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;With Big Data and AI, organizations will no longer need Data Scientists, Data Engineers No. I’m told similar things were said in the past for coders and the demand has only increased ever since. Data does not automagically analyze itself, no matter how much AI you inject. Let’s not confuse automatable tasks with the myth of self-learning, eloquently summarized by &lt;a href=&#34;https://hbr.org/2016/11/what-artificial-intelligence-can-and-cant-do-right-now&#34;&gt;Andrew Ng&lt;/a&gt;: &lt;em&gt;If a typical person can do a mental task with less than one second of thought, we can probably automate it using AI either now or in the near future.&lt;/em&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;With more data the task of organizing, curating, identifying, and preparing the data for analysis can only increase.&lt;/p&gt;
&lt;ol start=&#34;6&#34; style=&#34;list-style-type: decimal&#34;&gt;
&lt;li&gt;&lt;p&gt;Users will be able to interact with Big Data more easily I have no evidence of this, but I speculate that accessing data will be harder.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;The More the Data, the Better False. Maybe that’s true for the NSA (though even for them, I have some doubts). But most organizations do not have the deep pockets of a secretive government organization. Predictive models are usually built on samples: seldom is the whole data ever needed. There are also problems with having too large of a dataset, that to this day, we have not quite solved yet. Curse of large numbers.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Open Source is key for Big Data True. When one looks at the building blocks of most Big Data technology, they will soon realize it’s an ocean of open source initiatives without which we probably would not be having this conversation.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Data Science in the Organization: Things I Learned in 2016</title>
      <link>https://alternative-stats.netlify.com/post/2015-07-23-r-rmarkdown.html</link>
      <pubDate>Fri, 30 Dec 2016 21:13:14 -0500</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/2015-07-23-r-rmarkdown.html</guid>
      <description>&lt;div id=&#34;user-2016&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;useR! 2016&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;stanford.jpg&#34; /&gt; The &lt;a href=&#34;http://user2016.org/&#34;&gt;useR! conference&lt;/a&gt; in Stanford was awesome. Never did I expect to see so many participants (read: data geeks) and high level &lt;a href=&#34;http://user2016.org/#sponsors&#34;&gt;sponsors&lt;/a&gt;. For what was a little known language that’s been around in one form or another since the late seventies, this is quite amazing. Some memorable talks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;People are doing really amazing things with &lt;strong&gt;Shiny&lt;/strong&gt;. I was amazed at the pervasiveness of Shiny at &lt;a href=&#34;http://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/RServer-Operationalizing-R-at-Electronic-Arts&#34;&gt;EA Games&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;R’s superhero &lt;strong&gt;Hadley Whickham&lt;/strong&gt;, never takes a break. His idea is to create a “&lt;a href=&#34;http://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Towards-a-grammar-of-interactive-graphics&#34;&gt;pit of success&lt;/a&gt;” by having a uniform approach to import, tidy, transform, visualize, model and communicate.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Daniela Witten methodology on &lt;strong&gt;&lt;a href=&#34;http://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Flexible-and-Interpretable-Regression-Using-Convex-Penalties&#34;&gt;interpretable regression using convex penalties&lt;/a&gt;&lt;/strong&gt;: as I see it, it’s an attempt to do the least damage when people want simple interpretation of non-linear coefficients.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tal Galili gave a great presentation on &lt;strong&gt;&lt;a href=&#34;http://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Heatmaps-in-R-Overview-and-best-practices&#34;&gt;heatmaps&lt;/a&gt;&lt;/strong&gt; in R&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Rick Beckett on &lt;strong&gt;&lt;a href=&#34;http://channel9.msdn.com/Events/useR-international-R-User-conference/useR2016/Forty-years-of-S&#34;&gt;40 years of S&lt;/a&gt;&lt;/strong&gt; was fascinating: now I understand why the assignment operator in R is &lt;code&gt;&amp;lt;-&lt;/code&gt; (hint: jump to 0:29:00). We also learned that S and UNIX were two Bell Labs projects that grew together. Ironic how both took a while to be picked up and both grew into massively popular platforms (Linux, R).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-driven-decisions&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data-Driven Decisions&lt;/h1&gt;
&lt;p&gt;As a long-time data practitioner, I don’t get the cult-like infatuation with the term “data-driven” decisions (see here, here or here). Really folks: in the best case scenario we go from: data to evidence to decisions. If we want to go from data to decisions, hope for the best, because science may not back you up.&lt;/p&gt;
&lt;p&gt;In health research, the term “data driven” has negative connotations. Instead, we have a much more scientifically sound **[evidence-based]*(&lt;a href=&#34;http://en.wikipedia.org/wiki/Evidence-based_medicine)*&#34; class=&#34;uri&#34;&gt;http://en.wikipedia.org/wiki/Evidence-based_medicine)*&lt;/a&gt; approach.&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;evidence_based.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;A recent study suggests that &lt;a href=&#34;http://jamanetwork.com/journals/jamainternalmedicine/article-abstract/2593252&#34;&gt;women make better doctors than men&lt;/a&gt; (also &lt;a href=&#34;http://www.theatlantic.com/health/archive/2016/12/female-doctors-superiority/511034/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;http://www.nbcnews.com/health/health-news/female-doctors-outperform-male-doctors-according-study-n697876&#34;&gt;here&lt;/a&gt;). There are &lt;a href=&#34;http://stream.org/whos-better-playing-doctor-boys-girls/&#34;&gt;many problems&lt;/a&gt; with this study. But it got me thinking of a way to explain how “data driven” can be dangerous: if women are better doctor because they treated many fewer patients than men and, therefore, had more time to spend with patients, then, the data-driven decision of having more women doctors won’t lead to improved health outcomes. But, hey, it’s “data driven”!&lt;/p&gt;
&lt;p&gt;This echos well-known statistician &lt;a href=&#34;http://vkc.mc.vanderbilt.edu/people/harrell-frank&#34;&gt;Frank Harrell&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Using the data to guide the data analysis is almost as dangerous as not doing so“.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;ethics-ethics-ethics&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Ethics, Ethics, Ethics&lt;/h1&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;ethics.jpg&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;The ties between &lt;strong&gt;statistics and ethics&lt;/strong&gt; are well known (see &lt;a href=&#34;http://www.jstor.org/stable/3564481?seq=1#page_scan_tab_contents&#34;&gt;here&lt;/a&gt;). Nearly every PhD biostatistician I know has sat on an ethics board at some points in their careers. Now, it seems that the broader field of &lt;strong&gt;Data Science is starting to pay attention to the ethical implications of their work&lt;/strong&gt;. A few key events:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A great article on ProPublica on &lt;a href=&#34;http://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing&#34;&gt;predictive sentencing&lt;/a&gt; in the US.&lt;/li&gt;
&lt;li&gt;More and more &lt;a href=&#34;http://www.edx.org/course/data-science-ethics-michiganx-ds101x-1&#34;&gt;courses&lt;/a&gt; on ethics in data science are starting to emerge&lt;/li&gt;
&lt;li&gt;Cathy O’Neal’s book “&lt;a href=&#34;http://blogs.scientificamerican.com/roots-of-unity/review-weapons-of-math-destruction/&#34;&gt;Weapon of Math Destruction: How Big Data Increases Inequality and Threatens Democracy&lt;/a&gt;” is on my &lt;a href=&#34;http://a.co/0weW8WA&#34;&gt;Amazon wish list&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Google provides one of the &lt;a href=&#34;http://research.google.com/bigpicture/attacking-discrimination-in-ml/&#34;&gt;best explanations&lt;/a&gt; I have seen on the difficulty of making fair decisions. As &lt;a href=&#34;http://www.statschat.org.nz/2017/01/01/kinds-of-fairness-worth-working-for/&#34;&gt;Thomas Lumley&lt;/a&gt; writes: “&lt;strong&gt;You have to decide what summary of the difference you care about, because you can’t make them all the same&lt;/strong&gt;. This is old news in medical diagnostics, but appears not to have been considered in some other areas”.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;unicorns&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Unicorns&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://s-media-cache-ak0.pinimg.com/736x/9d/0e/e6/9d0ee6c0049e088172590e0d81b1684c--polygon-art-diy-paper.jpg&#34; /&gt; This year has confirmed that Data Science is a &lt;strong&gt;wide and broad field&lt;/strong&gt;, just like Medicine, Law or Engineering: many flavours, many specializations. Sorry folks, &lt;strong&gt;unicorns who are specialist in everything do not exist&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Just like hospitals do not hire a family physicians and expect them to do the work of 100 specialists, just like we don’t hire a criminal lawyer when we need a tax lawyer, organizations cannot expect to hire one data scientist generalist and do the work of 100 specialists. &lt;a href=&#34;http://drewconway.com/zia/2013/7/18/warning-do-not-feed-the-wildebeests&#34;&gt;&lt;strong&gt;Diversity&lt;/strong&gt;&lt;/a&gt; is key.&lt;/p&gt;
&lt;p&gt;And let’s not fall into the trap of judging a Data Scientist by the &lt;strong&gt;mathematical or algorithmic sophistication&lt;/strong&gt; of their arsenals. In the words of &lt;a href=&#34;http://en.wikipedia.org/wiki/Daniel_Kahneman&#34;&gt;Kahneman&lt;/a&gt;, we would be substituting a question which we cannot answer with a different one which we can answer.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;automation-model-factories&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Automation &amp;amp; Model Factories&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;automation.png&#34; /&gt; Automation is really misunderstood. Really. I was pointed to &lt;strong&gt;Tom Davenport’s&lt;/strong&gt; article on “&lt;a href=&#34;http://www.linkedin.com/pulse/move-your-analytics-operation-from-artisanal-tom-davenport?trk=hp-feed-article-title-like&#34;&gt;Autonomous Analytics&lt;/a&gt;” and the concept of &lt;strong&gt;model factory&lt;/strong&gt; as described in &lt;a href=&#34;http://www.youtube.com/watch?v=yNfsnv9gjrU&#34;&gt;this video&lt;/a&gt;. It’s a great article and agree with pretty much everything. It’s what it &lt;strong&gt;does not say&lt;/strong&gt; that concerns me. I commented in Tom’s article, but briefly:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Not everything is worth automating (e.g. single points decisions)&lt;/li&gt;
&lt;li&gt;Not everything is automatable (causal models, explanatory models, exploratory analysis)&lt;/li&gt;
&lt;li&gt;Automation is more of an IT problem than a Data Science one (see &lt;strong&gt;Diego Kuonen’s&lt;/strong&gt; fantastic slides on &lt;a href=&#34;http://www.slideshare.net/kuonen/demystifying-big-data-data-science-and-statistics-along-with-machine-intelligence-and-learning&#34;&gt;Demystifying Big Data, Data Science and Statistics&lt;/a&gt;). &lt;em&gt;Which means it is the last mile of a repetitive insight generation process the mechanisms of which are well understood and that applies to a well understood class of problems (predictive)&lt;/em&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-wrangling&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data Wrangling&lt;/h1&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;data_wrangling.jpg&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nytimes.com/2014/08/18/technology/for-big-data-scientists-hurdle-to-insights-is-janitor-work.html?_r=0&#34;&gt;Data munging/carpentry/wrangling&lt;/a&gt;, you know, that tedious, time consuming work that &lt;strong&gt;takes some 80% of a data scientist’s time&lt;/strong&gt; is (still) not given enough credit by evangelists, vendors, consultants and speakers. Not sexy? Sure, but it’s a reality we must face nonetheless.&lt;/p&gt;
&lt;p&gt;What’s more, is hardly automatable (see above) and the &lt;a href=&#34;http://www.oreilly.com/ideas/why-data-preparation-frameworks-rely-on-human-in-the-loop-systems&#34;&gt;human-in-the-loop&lt;/a&gt; provides myriads of necessary context and judgement calls that machines cannot make. I bet this has caused a lot of misunderstanding in organizations: “&lt;em&gt;What? Are you trying to tell me we spent $100K for that fancy analytics software and it’s useless?&lt;/em&gt;”&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analytical-maturity&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Analytical Maturity&lt;/h1&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;http://xolotl.org/wp-content/uploads/2016/11/7159036564_ec69766fe7_o.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;If the keywords and verbiage used by organizations to advertise their data related jobs are any indication of their &lt;strong&gt;analytical maturity&lt;/strong&gt;, there are promising signs! I work in the energy sector, not Silicon Valley, which means it takes a little while for us to pick up on technological or scientific innovations. For the past four years, I received weekly job alerts and, anecdotally, I can say that the expectations, clarity and keywords of the ad have improved significantly.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;analytics-podcasts&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Analytics Podcasts&lt;/h1&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;https://media.licdn.com/mpr/mpr/AAEAAQAAAAAAAAh-AAAAJGMxOWY3NzViLWEwYmItNDBkOS1iNDc3LTkyYTA5OGFmYjA4ZQ.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;The number of really good analytics podcasts has grown significantly, to the point I can barely keep up.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://soundcloud.com/nssd-podcast&#34;&gt;Not So Standard Deviation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://dataskeptic.com/&#34;&gt;The Data Skeptic Podcast&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://partiallyderivative.com/&#34;&gt;Partially Derivative&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://datastori.es/&#34;&gt;Data Stories&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.oreilly.com/topics/oreilly-data-show-podcast&#34;&gt;O’Reilly Data Show&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.thetalkingmachines.com/&#34;&gt;Talking Machines&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Not So Standard Deviations and O’Reilly Data Show are great detox if you are subject to a considerable amount of timeshare-sque-like products and hyperbolic claims by vendors or consultants.&lt;/p&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>One Common Mistake Data Analysts Make and How to Avoid It</title>
      <link>https://alternative-stats.netlify.com/post/one-common-mistake-data-analysts-make-and-how-to-avoid-it.html</link>
      <pubDate>Tue, 19 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/one-common-mistake-data-analysts-make-and-how-to-avoid-it.html</guid>
      <description>&lt;p&gt;One common mistake inexperienced analyst do in analysing data is that of &lt;strong&gt;assigning a special role to time&lt;/strong&gt;. In my line of work, I see this a lot. Signs of &lt;em&gt;chronophrenia&lt;/em&gt;, a term I just made up, are the unusual focus on calendar time: from line plots of multiple variables on the y-axis against time on the x-axis, to frequencies or averages by some meaningful time cut-off: monthly, quarterly, yearly and so on.&lt;/p&gt;
&lt;p&gt;Don’t get me wrong, I think there are plenty of scenarios when looking at time makes perfect sense and both the statistical, engineering and econometric literature continue to make substantial contributions to this area (I can think of &lt;a href=&#34;https://en.wikipedia.org/wiki/Change_detection&#34;&gt;change point detection&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Kalman_filter&#34;&gt;Kalman filters&lt;/a&gt; and &lt;a href=&#34;http://www.springer.com/cda/content/document/cda_downloaddocument/9780387772370-c1.pdf?SGWID=0-0-45-771009-p173891512&#34;&gt;Bayesian/Dynamic time series&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Often the analyst attempts to visually assess whether a &lt;strong&gt;shift in time exists&lt;/strong&gt;. The hope is that the shift can be tied to a special cause known to the analyst (for instance a change that was introduced at known point in time) and that this would represent evidence in favour or against a hypothesis.&lt;/p&gt;
&lt;p&gt;There are a number of drawbacks with this approach. Here I will list a few common ones:&lt;/p&gt;
&lt;p&gt;How do we know whether a change in time is due to some special cause that happens at a know time, or whether is due to normal variation? In these settings SPC is limited.&lt;/p&gt;
&lt;p&gt;Time does not possess magical properties: in most fields, seldom is time on the causal pathway. In other words, time does not cause much. Ok, there are some exceptions, however, at best, time is a proxy measure for something we are unable to measure. Think about it: how many times can we think of time having caused something? Death? Not really: trauma, or the inability of cells to reproduce reliably are some of the underlying causes. An old engine breaking down? Think fatigue, structural failure, wear and tear. Changing jobs? Think of complex social issues.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Once you do fully understand a process, time plays no role (Cleves et al.)&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Suppose we introduce some change at a known point in time. The analyst proceeds to compare, often visually, whether a slope or a shift change occurs. The approach is limited unless we can somehow freeze everything else.&lt;/p&gt;
&lt;p&gt;To an untrained analyst, time is an open invitation to slice and dice the data until some interesting results are found: we will always find a reason for looking at things daily, weekly, monthly, quarterly, yearly. These are in fact, meaningful measures to a lot of businesses. Eventually, you are guaranteed to find something interesting or even significant. But it does not mean it’s true. But wait! Don’t take my word for it! &lt;a href=&#34;http://www.tylervigen.com/spurious-correlations&#34;&gt;Tyler Vigen&lt;/a&gt; assembled a very humorous collection of &lt;strong&gt;spurious correlations&lt;/strong&gt;. Vigen had enough material to fill a whole book. You don’t have to buy his book, though I would encourage you to do so. Some are available on Vigen’s website.&lt;/p&gt;
&lt;p&gt;Visualization pioneer Edward Tufte has a very effective visual demonstration on &lt;strong&gt;streak-guessing&lt;/strong&gt; and &lt;strong&gt;over-narrative&lt;/strong&gt; around time (here, adapted from the &lt;a href=&#34;https://www.edwardtufte.com/bboard/q-and-a-fetch-msg?msg_id=0001OR&#34;&gt;original&lt;/a&gt;). On the top figure we see the actual win-loss record. At the bottom, notice what happens when we randomize the order on time.&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;winning_streak_1.png&#34; /&gt; &lt;em&gt;2009 Boston Red Sox win-loss record: when 4 or more wins occurs one after the other, the series is drawn in red. The causal attribution of win or loss streaks result in over-narratives.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;div class=&#34;figure&#34;&gt;
&lt;img src=&#34;winning_streak_2.png&#34; /&gt;

&lt;/div&gt;
&lt;p&gt;&lt;em&gt;Not so fast: 3 randomized samples from the same data. There is little evidence for a causal mechanism of win or loss streaks that in the original series resulted in over-narratives. The invisible hand of chance.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;br&gt;&lt;br&gt;&lt;/p&gt;
&lt;p&gt;So, enough about ranting against time. Let me play devil’s advocate and list some arguments in favour of time:&lt;/p&gt;
&lt;p&gt;When we do not understand a process, time is often a good proxy for something we are unable to measure. We should try to smooth time to detect trends. I’m a fan of LOESS for its flexibility.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;loess.gif&#34; alt=&#34;LOESS&#34; /&gt; LOESS (image from &lt;a href=&#34;https://simplystatistics.org/2017/08/08/code-for-my-educational-gifs/&#34;&gt;Simply Statistics&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Survival analysis (time to event analysis) is mostly concerned with the rate at which things are moving. Is a certain group reaching an event faster than another group? Survival analysis can effectively deal with survivorship bias.&lt;/p&gt;
&lt;p&gt;When we introduce a change at a given time point, there are methods that try to deal with it, such as interrupted time series or &lt;a href=&#34;https://en.wikipedia.org/wiki/Change_detection&#34;&gt;change point detection&lt;/a&gt; (these can go by different names). For an overview, see Kontopantelis. Change point detection is an active area of research.&lt;/p&gt;
&lt;p&gt;If you are embarking on an analysis, don’t jump on time as your first go-to measure. Think carefully about the problem and try first to identify all factors that may affect a response of interest. Explore those first, plot them against the response, plot them against each other. Try to learn as much about your problem without recurring to time immediately. When you do look at time, remember there are challenges unique to times that complicates things (autocorrelation and censoring to name a couple).&lt;/p&gt;
&lt;p&gt;Remember: “&lt;em&gt;Once you do fully understand a process, time plays no role&lt;/em&gt;” … or almost.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Time to Embrace a New Identity?</title>
      <link>https://alternative-stats.netlify.com/post/time-to-embrace-a-new-identity.html</link>
      <pubDate>Wed, 01 Oct 2014 00:00:00 +0000</pubDate>
      
      <guid>https://alternative-stats.netlify.com/post/time-to-embrace-a-new-identity.html</guid>
      <description>&lt;p&gt;&lt;em&gt;First published in &lt;a href=&#34;https://ssc.ca/en/vol-283-august-2014&#34;&gt;SSC Liason&lt;/a&gt;, &lt;a href=&#34;http://magazine.amstat.org/blog/2014/10/01/statview-oct14/&#34;&gt;Amstat News&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;There is no question in my mind that statisticians are crossing a sea of changes. As a profession, we have made high-quality contributions to many fields over the past decades, with our engagement being perfectly epitomized in the recent book Statistics in Action: A Canadian Outlook. However, one cannot help but notice the recent trends (and hype) in the closely aligned—and somewhat vaguely defined—fields of analytics, Big Data, data science, and machine learning and wonder if our current model will continue to do well.&lt;/p&gt;
&lt;p&gt;As a statistician, I am concerned. As a professional who recently migrated from the cancer research “sandbox” to the energy industry “sandbox,” I am facing numerous challenges associated with poor statistical literacy and the burden of the image problem we suffer from, which was so well captured by Brian Everitt in his book, Chance Rules: An Informal Guide to Probability, Risk, and Statistics: “[Statistics] conjures either a near-sighted character amassing volumes of figures about cricketers’ bowling and batting averages […] or a government civil servant compiling massive tables of figures” Hype aside, we are seeing a distortion of our field, the reinvention of many concepts, and the sad disregard of our contributions—often by those who do not analyze data professionally.&lt;/p&gt;
&lt;p&gt;Because I happen to believe that many of our members and colleagues are insulated from what goes on outside of their fields, we may not fully understand the repercussions these events can have on our future. Hence, I feel compelled to list a few examples:&lt;/p&gt;
&lt;p&gt;First, consider the consulting firm McKinsey &amp;amp; Company, which wrote a report on Big Data in 2011. On Page 28, they list the techniques to analyze Big Data as mostly coming from the field of machine learning. However, I count at least 11 techniques that were developed in the field of statistics. On Page 30, regression, predictive modeling, and statistics are separate entities. And that’s not all. On Page 47, the authors list the new R&amp;amp;D opportunity in health care as “analyzing clinical trials data.” Does this imply we have not been analyzing clinical trials in the past? Now, to put this into perspective, consider how influential and trusted McKinsey is. Add the low statistical literacy of most organizations and we have a problem: Treating this field as novel ignores nearly 300 years of statistical history, and most people looking into Big Data won’t realize that.&lt;/p&gt;
&lt;p&gt;Second, the machine learning attitude toward statistics is worrisome. All too often, we observe bright computer scientists who can pick up computational aspects of our work, yet rarely possess the solid statistical foundations needed to properly tackle the problem—from poor research methods to ignoring uncertainty. In a guest blog post on FierceBigData, ASA Executive Director Ronald Wasserstein wrote, “Are the data collected in a way that introduces bias? Are there missing or incomplete data? Are there different kinds of data? Statisticians not only know how to ask the right questions, but may have practical solutions already available.” There are plenty of examples of this attitude, especially on the popular forum Cross Validated. In turn, this leads to provocative articles such as “The Death of the Statistician” and “Is Data Science the End of Statistics? A Discussion.”&lt;/p&gt;
&lt;p&gt;Third, many things are being reinvented. Bradley Efron once said, “Statistics is the science of learning from experience. Those who ignore statistics are condemned to reinvent it.” According to Wikipedia, logistic regression is a classifier. More recently, Hadley Wickham noticed how nearly 50 years of statistical smoothing literature has had little effect on information visualization, which had to reinvent the wheel.&lt;/p&gt;
&lt;p&gt;Fourth, as Randy Bartlett explains in A Practitioner’s Guide to Business Analytics, making data analysis software more user-friendly has opened the flood gates holding back statistical malfeasances. The desire to simplify tools, methods, and solutions for use by business users has led to what some people refer to as a culture of “buttonology.” Frank Harrell had this to say: “What I most fear is that statistics wasn’t respected enough before the machine learning field went viral, and things have just gone from bad to worse. The ready availability of software has hurt.”&lt;/p&gt;
&lt;p&gt;Fifth, false novelty is feeding reinvention. Consider Terry Speed’s talk on Big Data, for instance, in which he gave a memorable example. A University of California alumni magazine article on Big Data showed an empty row for statistics. Economics, chemistry, marketing, computer science? All there. Statistics? Nope. And to add insult to injury, they have not forgotten it; it’s simply empty, as if statistics contributed nothing. I echo what Jeff Leek wrote on his Simply Statistics blog: This “shows a fundamental disrespect for applied statisticians who have developed serious expertise in a range of scientific disciplines.”&lt;/p&gt;
&lt;p&gt;A recent report on the future of the statistical sciences says, “Statisticians, with some prominent exceptions, also have been unwilling or unable to communicate to the rest of the world the value (and excitement) of their work.” This sentence hints at the consequences we may face if we do not act quickly: We may never have existed in the eyes of many and our contributions may be reinvented and re-packaged in a different field.&lt;/p&gt;
&lt;p&gt;Also, the report confirms challenges we have never faced in the past: “Undoubtedly the greatest challenge and opportunity that confronts today’s statisticians is the rise of Big Data.” While some think these trends will “eventually fade,” as they did in the data mining movement of the ’90s, I believe there is too much economic interest for it to simply fade away. If the numbers of analytics software and languages are any indication of things to come, this movement is hardly going to fade.&lt;/p&gt;
&lt;p&gt;I am convinced that despite the misguided direction and pitfalls, the focus and attention on Big Data (or data science) is mostly a good thing. Sure, Big Data is not going to change those organizations and research institutions that have been doing this work for decades. However, it will inevitably bring a more evidence-based approach to the way companies do business and the government makes policies. This progress, however, may come at a price.&lt;/p&gt;
&lt;p&gt;Statistical certification is largely unrecognized outside academic and research institutions. I suspect this was meant to protect us from the very improvised statisticians who contributed to the bad image. It may have worked, if things stayed the same. I think we are falling victim to the complacency of our own culture. Perhaps, ASA Past President Robert Rodriguez saw this coming when he suggested we use the big tent approach.&lt;/p&gt;
&lt;p&gt;Doing nothing and hoping problems will fade away is not a good strategy.&lt;/p&gt;
&lt;p&gt;First, this is going to hurt us because we cannot properly assert our knowledge and contributions against parallel fields with a much more rapid mechanism of spreading new ideas (e.g., conference proceedings are typical in CS/ML vs. peer-review in statistics).&lt;/p&gt;
&lt;p&gt;Second, our lack of notoriety in other fields may deprive our departments and professors of the needed funding and recognition.&lt;/p&gt;
&lt;p&gt;Third, we have been unable or unwilling to prepare the next generation of applied statisticians for a work place that might change substantially. At present, statistics departments are reluctant to incorporate feedback from applied statisticians in the field. Applied statisticians must finish their basic training after graduate school. )Fourth, a multitude of certifications are now being established to monetize on the recent data movement. Should we not be at the forefront of this? Shouldn’t our certifications be the highest regarded owing to our nearly 300-year history? INFORMS (an operation research organization) is aggressively pushing their certification, CAP, which is establishing itself as the certification for analytics. A quick scan of its content reveals it covers a blend of data management and data analysis.&lt;/p&gt;
&lt;p&gt;There are multiple ways we can become more engaged. At a minimum, acknowledging and talking about these issues is a first step. Here are a few ideas.&lt;/p&gt;
&lt;p&gt;Consider being active on social media. There are numerous venues to show the rest of the world the value and excitement of our work: Stack Exchange, LinkedIn, Twitter, Facebook, Quora, and the many fora specific to statistical software packages are some of the most obvious choices. I am part of a team founding About Data Analysis (ADA), a new LinkedIn discussion group specific to data analysis issues. Consider stepping outside of your comfort zone. For example, many of the methods we commonly use are now being used in other fields (e.g., survival analysis in marketing). Why not speak at conferences outside your sandbox to those who are starting to use the very methods we have mastered? Consider making some of your work openly available. Write a blog or an open-access paper. If a paper was not accepted at a journal, why not make it freely available? If you teach, consider approaching your department about making video tutorials. Look at the work of Jeff Leek and Roger Peng for examples. If you have videos of your conference presentation, make them available. As a profession, we should explore diversifying our certifications programs or joining forces with similar and reputable professional organizations. As a profession, we need to have the courage to look outside the wall that has so far protected us from unscrupulous intruders. As Randy Bartlett wrote in Amstat News, “[T]o differentiate our value proposition, we must be involved.” We need to involve ourselves with other parallel fields, learn about their problems, and share existing solutions. This does not mean lowering our standards for rigorous results. We cannot defend our profession and retain our current customers by building walls meant to keep the barbarians out. We need to empower our applied statisticians with certification and more applied training. Furthermore, we need to build bridges to support their entrance into other fields.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
